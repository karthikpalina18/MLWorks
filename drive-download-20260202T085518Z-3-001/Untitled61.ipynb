{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7KoQXWNyw9Pqo1hswFG4X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Toxag3Sqnuvn","executionInfo":{"status":"ok","timestamp":1758889362481,"user_tz":-330,"elapsed":38951,"user":{"displayName":"Palina Karthik","userId":"10747662337054099299"}},"outputId":"a543587b-f009-4c16-f5d3-c15188382792"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","Input[0:3]: [ 1.28770177 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: 0.000, z: 0.000, Pred: 1, Updated Bias: -0.010\n","Input[0:3]: [-0.33638447 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: 0.023, z: 0.013, Pred: 1, Updated Bias: -0.020\n","Input[0:3]: [-0.40325332  1.01327135 -0.71521823]..., Target: 0, Weighted Sum: 0.065, z: 0.045, Pred: 1, Updated Bias: -0.030\n","Input[0:3]: [ 0.38822983 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.006, z: -0.036, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.32528234 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.037, z: -0.067, Pred: 0, Updated Bias: -0.030\n","\n","Epoch 2\n","Input[0:3]: [ 1.28770177 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.053, z: -0.083, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.33638447 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.039, z: -0.069, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.40325332  1.01327135 -0.71521823]..., Target: 0, Weighted Sum: -0.030, z: -0.060, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [ 0.38822983 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.006, z: -0.036, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.32528234 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.037, z: -0.067, Pred: 0, Updated Bias: -0.030\n","\n","Epoch 3\n","Input[0:3]: [ 1.28770177 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.053, z: -0.083, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.33638447 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.039, z: -0.069, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.40325332  1.01327135 -0.71521823]..., Target: 0, Weighted Sum: -0.030, z: -0.060, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [ 0.38822983 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.006, z: -0.036, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.32528234 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.037, z: -0.067, Pred: 0, Updated Bias: -0.030\n","\n","Epoch 4\n","Input[0:3]: [ 1.28770177 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.053, z: -0.083, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.33638447 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.039, z: -0.069, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.40325332  1.01327135 -0.71521823]..., Target: 0, Weighted Sum: -0.030, z: -0.060, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [ 0.38822983 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.006, z: -0.036, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.32528234 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.037, z: -0.067, Pred: 0, Updated Bias: -0.030\n","\n","Epoch 5\n","Input[0:3]: [ 1.28770177 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.053, z: -0.083, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.33638447 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.039, z: -0.069, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.40325332  1.01327135 -0.71521823]..., Target: 0, Weighted Sum: -0.030, z: -0.060, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [ 0.38822983 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.006, z: -0.036, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.32528234 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.037, z: -0.067, Pred: 0, Updated Bias: -0.030\n","\n","Epoch 6\n","Input[0:3]: [ 1.28770177 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.053, z: -0.083, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.33638447 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.039, z: -0.069, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.40325332  1.01327135 -0.71521823]..., Target: 0, Weighted Sum: -0.030, z: -0.060, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [ 0.38822983 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.006, z: -0.036, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.32528234 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.037, z: -0.067, Pred: 0, Updated Bias: -0.030\n","\n","Epoch 7\n","Input[0:3]: [ 1.28770177 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.053, z: -0.083, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.33638447 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.039, z: -0.069, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.40325332  1.01327135 -0.71521823]..., Target: 0, Weighted Sum: -0.030, z: -0.060, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [ 0.38822983 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.006, z: -0.036, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.32528234 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.037, z: -0.067, Pred: 0, Updated Bias: -0.030\n","\n","Epoch 8\n","Input[0:3]: [ 1.28770177 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.053, z: -0.083, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.33638447 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.039, z: -0.069, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.40325332  1.01327135 -0.71521823]..., Target: 0, Weighted Sum: -0.030, z: -0.060, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [ 0.38822983 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.006, z: -0.036, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.32528234 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.037, z: -0.067, Pred: 0, Updated Bias: -0.030\n","\n","Epoch 9\n","Input[0:3]: [ 1.28770177 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.053, z: -0.083, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.33638447 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.039, z: -0.069, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.40325332  1.01327135 -0.71521823]..., Target: 0, Weighted Sum: -0.030, z: -0.060, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [ 0.38822983 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.006, z: -0.036, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.32528234 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.037, z: -0.067, Pred: 0, Updated Bias: -0.030\n","\n","Epoch 10\n","Input[0:3]: [ 1.28770177 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.053, z: -0.083, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.33638447 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.039, z: -0.069, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.40325332  1.01327135 -0.71521823]..., Target: 0, Weighted Sum: -0.030, z: -0.060, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [ 0.38822983 -0.50032012  1.03323679]..., Target: 0, Weighted Sum: -0.006, z: -0.036, Pred: 0, Updated Bias: -0.030\n","Input[0:3]: [-0.32528234 -0.50032012 -0.41315956]..., Target: 0, Weighted Sum: -0.037, z: -0.067, Pred: 0, Updated Bias: -0.030\n","\n","Final Results:\n","Accuracy: 0.6667\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.64      0.98      0.78        60\n","           1       0.90      0.21      0.35        42\n","\n","    accuracy                           0.67       102\n","   macro avg       0.77      0.60      0.56       102\n","weighted avg       0.75      0.67      0.60       102\n","\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# -----------------------\n","# 1. Load Boston Dataset\n","# -----------------------\n","boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n","X = boston.data.values\n","y = boston.target.astype(float).values\n","\n","# Convert regression target into binary classification\n","# Above median = 1 (high price), else 0 (low price)\n","median_value = np.median(y)\n","y = (y > median_value).astype(int)\n","\n","# Split train/test\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# -----------------------\n","# 2. Initialize Perceptron\n","# -----------------------\n","weights = np.zeros(X_train.shape[1])  # one weight per feature\n","bias = 0.0\n","learning_rate = 0.01\n","epochs = 10  # small number to show steps\n","\n","# Activation function (step)\n","def activation(z):\n","    return 1 if z >= 0 else 0\n","\n","# -----------------------\n","# 3. Training (Step-by-Step Print)\n","# -----------------------\n","for epoch in range(epochs):\n","    print(f\"\\nEpoch {epoch+1}\")\n","    for i in range(5):  # print only first 5 samples per epoch\n","        xi = X_train[i]\n","        target = y_train[i]\n","\n","        # Step 3: Weighted sum\n","        weighted_sum = np.dot(xi, weights)\n","\n","        # Step 4: Add bias\n","        z = weighted_sum + bias\n","\n","        # Step 5: Activation\n","        y_pred = activation(z)\n","\n","        # Update rule\n","        update = learning_rate * (target - y_pred)\n","        weights += update * xi\n","        bias += update\n","\n","        print(f\"Input[0:3]: {xi[:3]}..., Target: {target}, \"\n","              f\"Weighted Sum: {weighted_sum:.3f}, z: {z:.3f}, \"\n","              f\"Pred: {y_pred}, Updated Bias: {bias:.3f}\")\n","\n","# -----------------------\n","# 4. Evaluation\n","# -----------------------\n","def predict(X):\n","    return np.array([activation(np.dot(xi, weights) + bias) for xi in X])\n","\n","y_pred = predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","report = classification_report(y_test, y_pred)\n","\n","print(\"\\nFinal Results:\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(\"Classification Report:\\n\", report)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"RwV3b7quv2y7"},"execution_count":null,"outputs":[]}]}